# 第08课 下载图片

## 一. 安装requests和pillow库

下载图片需要用到requests库，保存图片需要用到pillow库

`pip install -r requirements.txt`

![image-20220114195459091](image\image-20220114195459091.png)

## 二. 下载图片

2.1 创建图片存放目录

```python
    def run(self):
        """开始运行"""
        # ...
        # 下载所有图片
        self._download_all_image()
    def _download_all_image(self):
        """下载所有图片"""
        download_dir = f"{dirname(__file__)}/download/{strftime('%Y%m%d-%H%M%S')}-{self.keyword}"
        makedirs(download_dir)
```

2.2 下载图片

```python
    def _download_all_image(self):
        """下载所有图片"""
        # ...
        # 下载所有图片
        count = 0
        for download_link in self.all_download_link:
            # 下载图片
            response = requests.get(download_link)
            # response.content是字节串 response.text是字符串
            # 保存图片
            image = Image.open(BytesIO(response.content))
            count += 1
            filename = f"{str(count).rjust(6, '0')}.png"
            image_path = f"{download_dir}/{filename}"
            image.save(image_path)
            print(f"图片已保存：{image_path}")
```

> 备注：
>
> 1. Image要使用PIL.Image模块，而不是PIL.Image.Image类，
>
> 因为open是PIL.Image模块的一个函数；
>
> 2. 代码的组织方式有很多，大家也可以，在访问图片详情的时候，直接下载图片。

![image-20220114202751820](image\image-20220114202751820.png)

最终代码

```python
"""
图片资源自动搜索下载

@author  : zhouhuajian
@version : v1.0
"""
from io import BytesIO
from os import makedirs
from os.path import dirname
from time import strftime

import requests
from PIL import Image
from lxml.etree import HTML
from selenium import webdriver
from selenium.webdriver.common.keys import Keys


class ImageAutoSearchAndSave:
    """图片自动搜索保存"""

    def __init__(self, keyword, limit=0):
        """初始化"""
        self.driver = webdriver.Chrome(executable_path=dirname(__file__) + '/chromedriver.exe')
        self.keyword = keyword
        self.limit = limit  # 0表示没有限制
        self.count = 0
        self.all_image_detail_link = []
        self.all_download_link = []

    def run(self):
        """开始运行"""
        print("========= 开始 =========")
        # 访问首页
        self.driver.get("https://pixabay.com/")
        # 搜索图片
        self._search_image()
        # 遍历所有图片列表页面
        self._iter_all_page()
        # 访问图片详情
        self._visit_image_detail()
        # 释放资源、释放内存
        self.driver.close()
        del self.all_image_detail_link
        # 下载所有图片
        self._download_all_image()
        print("========= 结束 =========")

    def _search_image(self):
        """搜索图片"""
        elem = self.driver.find_element_by_css_selector("input[name]")
        elem.send_keys(self.keyword + Keys.ENTER)

    def _iter_all_page(self):
        """遍历所有图片列表页面"""
        # 获取页面总数
        elem = self.driver.find_element_by_css_selector("span[class^=total]")
        page_total = int(elem.text.strip("/ "))
        print(f"总页面数：{page_total}")
        # 遍历所有页面
        base_url = self.driver.current_url
        for page_num in range(1, page_total + 1):
            print(f"正在访问第{page_num}页")
            if page_num > 1:
                self.driver.get(f"{base_url}?pagi={page_num}&")
            # 获取一个页面的所有图片详情链接
            root = HTML(self.driver.page_source)
            image_detail_links = root.xpath(
                '//div[starts-with(@class, "results")]//a[starts-with(@class, "link")]/@href')
            # 遍历当前列表页面的所有图片详情链接
            is_reach_limit = False
            for detail_link in image_detail_links:
                self.all_image_detail_link.append(detail_link)
                self.count += 1
                if self.limit > 0 and self.count == self.limit:
                    is_reach_limit = True
                    print(f"已到达{self.limit}个图片详情链接的限制，结束收集")
                    break
            if is_reach_limit:
                break
        print(f"共收集{len(self.all_image_detail_link)}个图片详情链接")

    def _visit_image_detail(self):
        """访问图片详情"""
        for image_detail_link in self.all_image_detail_link:
            self.driver.get(image_detail_link)
            # 获取图片下载链接
            elem = self.driver.find_element_by_css_selector("#media_container > picture > img")
            download_link = elem.get_attribute("src")
            print(f"下载链接：{download_link}")
            self.all_download_link.append(download_link)

    def _download_all_image(self):
        """下载所有图片"""
        download_dir = f"{dirname(__file__)}/download/{strftime('%Y%m%d-%H%M%S')}-{self.keyword}"
        makedirs(download_dir)
        # 下载所有图片
        count = 0
        for download_link in self.all_download_link:
            response = requests.get(download_link)
            image = Image.open(BytesIO(response.content))
            count += 1
            filename = f"{str(count).rjust(6, '0')}.png"
            image_path = f"{download_dir}/{filename}"
            image.save(image_path)
            print(f"图片已保存：{image_path}")


if __name__ == '__main__':
    keyword = "sunflower"
    limit = 6
    ImageAutoSearchAndSave(keyword, limit).run()
```



